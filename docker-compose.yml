version: "3.9"

services:
  db-server:
    image: postgres:15.3
    container_name: ${DB_HOST}
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
      TZ: "Asia/Tokyo"
    ports:
      - 5432:5432
    volumes:
      - ./dat/db_server:/var/lib/postgresql/data

  pgadmin:
    container_name: pgadmin-server
    image: dpage/pgadmin4:7.5
    restart: always
    ports:
      - 81:80
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD}
    depends_on:
      - db-server
    volumes:
      - ./dat/pgadmin4:/var/lib/pgadmin

  ftp-server:
    image: stilliard/pure-ftpd:latest
    container_name: ftp-server
    ports:
      - "21:21"
      - "30000-30009:30000-30009"
    volumes:
      - ./dat/ftp/data:/home/ftpusers
      - ./dat/ftp/passwd:/etc/pure-ftpd/passwd
    environment:
      - PUBLICHOST=localhost
      - FTP_USER_NAME=${FTP_USER_NAME}
      - FTP_USER_PASS=${FTP_USER_PASS}
      - FTP_USER_HOME=/home/ftpusers
      - ADDED_FLAGS="--tls=2"
    restart: always

  tracking-server:
    container_name: mlflow-tracking-server
    build:
      context: ./tracking_server
      dockerfile: Dockerfile
      args:
        - POSTGRES_USER=${POSTGRES_USER}
        - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
        - DB_HOST=${DB_HOST}
        - DB_NAME=${DB_NAME}
        - DEFAULT_ARTIFACT_ROOT=ftp://${FTP_USER_NAME}:${FTP_USER_PASS}@${HOST_IP}/artifact_location
    image: mlflow-tracking:1.0
    restart: always
    ports:
      - "5000:5000"
    depends_on:
      - db-server
      - ftp-server

  my_app_base:
    container_name: my_app_base
    build:
      context: .
      dockerfile: ./base.Dockerfile
    image: my_app_base
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]

  dev_pycaret:
    container_name: dev_pycaret
    build:
      context: .
      dockerfile: ./dev_pycaret/Dockerfile
    image: python-pycaret
    volumes:
      - .:/workspace:cached
    tty: true
    stdin_open: true
    depends_on:
      - tracking-server
      - my_app_base
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]

  dev_h2o:
    container_name: dev_h2o
    build:
      context: .
      dockerfile: ./dev_h2o/Dockerfile
    image: python-h2o
    volumes:
      - .:/workspace:cached
    tty: true
    stdin_open: true
    ports:
      - "54321:54321"
    depends_on:
      - tracking-server
      - my_app_base
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]

  dev_autogluon:
    container_name: dev_autogluon
    build:
      context: .
      dockerfile: ./dev_autogluon/Dockerfile
    image: python-autogluon
    volumes:
      - .:/workspace:cached
    tty: true
    stdin_open: true
    depends_on:
      - tracking-server
      - my_app_base
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
  
  gpu_test:
    container_name: gpu_test
    # image: nvidia/cuda:12.2.0-base-ubuntu22.04
    image: nvidia/cuda:12.1.0-cudnn8-devel-ubuntu22.04
    #command: sh -c "which nvidia-smi && nvidia-smi"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    tty: true
